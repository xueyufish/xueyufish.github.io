---
layout:     post
title:      "智能运维"
date:       2018-12-22
author:     "余修忞(xueyufish)"
---

## 运维现状
1. 衡量系统可用性的三个指标:

* 平均故障修复时间(MTBF)：相邻两次故障之间的平均工作时间，通常是衡量一个产品可靠性的指标。
* 平均修复时间(MBF): 产品由故障状态转为工作状态时修复时间的平均值，即修复故障所需要的平均时间。
* 可用性(Avaliablity): 指在要求的外部资源得到保证的前提下，产品在规定时刻或时间之内出于可执行规定状态的能力。

2. 运维发展历程:
人工阶段 -> 工具和自动化阶段 -> 平台化阶段 -> 智能运维阶段

## 智能运维
智能运维不是跳跃发展过程，根基还是运维自动化、监控、数据收集、分析和处理等具体过程。主要有以下问题：

1. 海量数据的存储、分析和处理
大量产生的event: 服务器运行状况、资源占用情况、业务日志、异常、告警、状态报告

传统方式(sar、zabbix、zenoss)只能处理一部分，数据量大以后处理能力，二次开发能力有限。

需要对海量数据进行分类和处理，每一种分类都对应一种或多种数据处理、分析、存储方式，例如：
* 实时和非实时数据
* 格式化和非格式化数据
* 需要索引的和只需要运算的数据
* 全量和抽样数据
* 可视化和告警数据
……

2. 多维度、多数据源
1）多维度：
	一个event除包含常用的"时间"（何时发生）、"地点"（哪个服务器/组件）、"内容"（错误码、状态值）外，还应当包含地区、机房、服务池、业务线、服务、接口等。
	数据分析人员常需要使用各种维度、组合各种指标来生成报告、告警规则、Dashboard 等，所以是否支持多维度的数据存储和查询分析是衡量一个系统是否具有灵活性的重要指标。
	对多维度数据的处理，大多数时候是一个协议/模型的问题，例如: 1) 单一key中包含维度信息；2）在tag中标注不同维度

2）多数据源：指复杂场景下产生多种类型数据，或者数据用多种方式存储和处理，比如：
	* 监控数据： 时序数据库(RRD、 Whisper、 TSDB)
	* 告警事件： Redis
	* 分析报表： MySQL
	* 日志检索： ElasticSearch、Hadoop/Hive

3. 信息过载
大量的监控指标中发现有用的: 数据聚合、降维(聚类和分类)、标准化和归一化

4. 复杂业务模型下的故障定位
在复杂、异构和各种技术栈混杂的业务系统中，如果想定位故障和发现问题，在各个系统中必须有一个可追踪、共性的东西。比如：
1）日志标准化：日志包含约定的内容，能标识自己的业务线、服务层级
2）全链路追踪：TraceID 或 RequestID 应该能从发起方透传到后端，标识唯一请求
3）SLA规范：采用统一SLA约定，比如"响应时间"约定性能指标，"慢速比"衡量系统健康度

故障定位又称为告警关联、问题确定或故障分析，指通过分析观测到的征兆，找出产生这些征兆的真正原因。

## 开源数据采集技术
1. 数据采集工具对比

|             |  Flume    |  Filebeat  | Logstash  | Scribe    |
| ----------- | --------: | :-------:  | :------:  | :-------: |
| 语言        |  Java      |    Go     |   Ruby    |    C++    |
| 占用系统资源 |  一般      |   少      |    多      |    多     |
| 扩展性      |   好       |   好      |    好      |    难     |
| 日志过滤    |   支持      |  支持     |    支持    |   不支持  |
| 日志解析    |   不支持    |  不支持   |    支持    |   不支持   |

2. 轻量级采集工具Filebeat
https://www.elastic.co/guide/en/beats/filebeat/current/index.html

3. 日志采集解析工具Logstash

## 分布式消息队列
1. 开源消息队列对比与分析
1）ZeroMQ（http://zeromq.org/）
2）ActiveMQ（http://activemq.apache.org/）
3）RocketMQ（http://rocketmq.apache.org/）
4）RabbitMQ（http://www.rabbitmq.com/）
5）Kafka（http://kafka.apache.org/）

2. Kafka 安装与使用

3. 案例分析（微博广告业务）
1）日志采集
2) 实时结算
3）实时计算

## 大数据存储技术
1. 传统数据存储
采用集中式存储，每个终端和客户端仅负责数据的录入和输出，数据的存储和控制完全交由主机完成。 部署结构简单，日志接收服务器通过网络共享、rsync、网络传输技术等将日志集中到几台磁盘容量很大的大型主机上。

主要问题有：
* 性能问题：索引效率、网络传输性能等
* 成本激增：大型主机的成本高
* 单点问题：单台服务器存储，造成 存储和磁盘的 I/O 瓶颈和数据丢失风险
* 数据准确性：由于系统采用回滚写入方式，这种无序的频繁读写导致产生大量的磁盘碎片。长时间将严重影响存储系统的读写性能，甚至导致存储系统被锁定为只读状态。

2. 基于HDFS的分布式存储
1）分布式存储的定义
通过网络连接每台机器，使这些分散的存储资源构成一个虚拟的存储设备，数据分散在每台机器上的各个角落。

按数据存储模型，分布式存储服务分为：
* 文件模型(对应分布式文件系统): 如 GFS、 HDFS。
* 关系模型(对应分布式数据库系统): 如 Google Spanner、 OceanBase、 ClickHouse。
* 键值模型(NoSQL 系统)： Redis、 Memcache。

对于分布式存储，需要关注如下几点：
* 数据的分布和负载均衡。
* 存储系统的容错问题。 
* 系统的可扩展性。 
* 如何保障可靠性和准确性。
* 性能和容错能力。

2）HDFS 的基本原理
https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html

3) HDFS 不适合的场景
* 实时性要求较高；
* 小文件；

3. 分层存储
1）数据仓库
数据仓库特点:
* 面向主题： OLTP 多面向事务，OLAP多面向主题域
* 集成：数据是在对原有分散的数据抽取、清理的基础上经过系统加工、汇总和整理得到的
* 相对稳定： 查询多，修改删除少
* 反应历史变化

2）数据仓库组成：
* 数据仓库数据库： 支持海量数据和快速检索
* 数据抽取工具
* 元数据
* 访问工具
* 数据集市

3）数据仓库分层架构：
* 缓冲层（Buffer）
* 操作数据层（ODS, Operational Data Store）：
* 明细数据层（ DWD, Data Warehouse Detail）：
* 汇总数据层：
* 数据集市层：

## 大规模数据离线计算分析
1. 经典的离线计算
1）sed 和 awk
2）pandas
3）python 优势和不足

2. 分布式离线计算
mapreduce

## 实时计算框架
1. Spark streaming
2. Flink

## 时序数据库分析框架
1. Graphite
2. Druid
3. ClickHoue

## 机器学习框架 
TensorFlow

## 数据聚合与关联技术
聚合数据有两个层面，一是对数据的聚合运算(计数、平均、抽样等);二是多维度的聚合(在实际应用中维度通常指时间、地点、业务线、服务、接口等，它们也可以被称作"标签"，用来标注看待数据的不同角度)。

1. 聚合运算
常见的时序数据聚合运算工具：
* Statsd(https://github.com/etsy/statsd)
* Statsite(Statsd 的 C 语言实现，https://github.com/statsite/statsite)
* Collectd(https://github.com/collectd/collectd)

支持的数据/事件类型: Key/Value：不进行聚合运算，直接存储原值; Sampling：抽样数据; Gauges：固定值; Counter：计数类数据，一般会进行求和、累加; Timers：时间型数据; Sets：集合型数据; Multi-Metric Packets：批量数据。 

针对 Timers 类型的数据，可以做如下运算：Mean 求平均值；Min/Max：求最小值/最大值；Standard deviation：求方差；Median, P95, P99： 求中位数、95% 值、99% 值；Histograms：求直方图/柱状图；Sum：求累计值。

2. 多维度聚合
1) 用 "." 分隔的 Metric 组织方式，将所有的维度信息放在了指标名中，这样做的好处是很直观，Statsd 可以按照 "." 来分类聚合。
   例如： `Openapi.profile.*.{tc, yf, xd}.db.{m7365*, m3360*}.total_ count`
2) 用 Tag 来扩展维度，比如： `Metric: total_ count, IP: xx.xx.xx.xx, Tags: { interface: user_ show, service_ pool: webv2_ action, location: yf}, Value: 2000, Type: count`
Tags方式不受指标名长度的限制（ 指标名超过 255 字节会导致在某些 KV 存储系统中无法使用，比如 Memcached），可以任意扩展维度。 一些时序数据库（比如 OpenTSDB）就需要按照“ Tags” 来存储指标，如果使用 OpenTSDB，那么对于上面介绍的在 指标名中包含维度信息的情况，就需要增加一层（在 Statsd 层或 Relay 层）来专门拆分指标、提取 Tags，然后转换成 TSDB 格式存储。带 Tags 类的指标信息处理就不太适用 Statsd 直接计算了，一些实时流式计算框架如 Storm 等可以用来处理这类较复杂的 Metric 的聚合和运算，这就需要一定的开发量。

3. 降低维度

4. 数据关联

## 微博广告智能监控体系
1. 监控指标体系
1）机器指标：CPU、内存、磁盘IO、网络IO、磁盘空间
监控目的： 发现机器故障、限流、扩容

2）应用指标
* 基础应用指标: nginx请求状态及access日志和端口，MySQL数据库端口、Hadoop集群状态等
* 非基础应用指标: 某个服务端口、进程个数、业务日志抽取出的指标

3）业务指标
具体业务、产品指标，如日收入趋势、订单数、广告计划等业务层面指标

2. 功能设计原则
从平台化视角考虑，监控报警平台要解决的问题如下：
* 是否能指导 RD 快速定位问题。 
* 是否为业务发展的预估提供了参考。

从业务视角考虑，监控报警平台所要解决的核心问题主要有以下几个方面:
* 监控指标： 精准性和覆盖率。 
* 报警： 实效性和准确性。 
* 故障诊断。 
* 自动处理。 

从系统架构及设计视角考虑，监控报警平台要能解决如下几个方面。
* 大数据分析处理能力，包括数据采集、 ETL 和数据抽象分析。 
* 数据分析处理的实时性。 
* 大规模监控指标等时序数据存储、报警规则存储及报警触发。
* 高可用性。
* 数据聚合能力。

3. 整体架构
1）数据采集层
负责对系统日志、系统指标、业务日志、业务指标等数据进行实时采集。支持 Flume、 Scribe 等日志收集工具，也支持 Filebeat、 Metricbeat 等文件及指标收集工具。

2）数据分析层
负责将采集到的数据进行 ETL、预处理、分析和聚合。为了提高可用性，采集到的数据将同时被写入 HDFS 进行持久化，数据分析层可以根据需要，从 HDFS 中 Reload 数据并重新进行计算。另外，离线部分的监控预估模块会定时进行模型训练，并将训练后的 模型存储在 HDFS 中。 Alert trigger 模块负责根据报警规则进行报警触发监测。 

3）可视化层
经过分析处理的数据被写入可视化层的存储系统中（如 Druid、 Elasticsearch、 MySQL 及 ClickHouse）, 可视化层负责根据业务方需求, 对监控图表进行展示、配置和管理，以及对报警信息及规则进行管理。 另外，可视化层提供了 API，允许第三方通过 API 的方式获取聚合分析后的数据，以及对报警进行管理。
